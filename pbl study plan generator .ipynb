{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a44ef2-369e-4b8f-a0d2-c80e4f3ed2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n",
      "Index(['Student_ID', 'GPA', 'Learning_Style', 'Available_Hours_Per_Day',\n",
      "       'Free_Days_Per_Week', 'Subject_Count', 'Exam_Priority',\n",
      "       'Weak_Subjects_Count', 'Recommended_Hours_Per_Subject'],\n",
      "      dtype='object')\n",
      "   Student_ID   GPA Learning_Style  Available_Hours_Per_Day  \\\n",
      "0           1  5.63    Kinesthetic                        3   \n",
      "1           2  6.70       Auditory                        7   \n",
      "2           3  9.19       Auditory                        2   \n",
      "3           4  5.44       Auditory                        8   \n",
      "4           5  7.45       Auditory                        2   \n",
      "\n",
      "   Free_Days_Per_Week  Subject_Count Exam_Priority  Weak_Subjects_Count  \\\n",
      "0                   7              4           Low                    1   \n",
      "1                   4              4           Low                    1   \n",
      "2                   7              7           Low                    2   \n",
      "3                   6              8        Medium                    3   \n",
      "4                   5              6          High                    0   \n",
      "\n",
      "   Recommended_Hours_Per_Subject  \n",
      "0                           0.66  \n",
      "1                           0.88  \n",
      "2                           0.27  \n",
      "3                           1.11  \n",
      "4                           0.29  \n",
      "Student_ID                       0\n",
      "GPA                              0\n",
      "Learning_Style                   0\n",
      "Available_Hours_Per_Day          0\n",
      "Free_Days_Per_Week               0\n",
      "Subject_Count                    0\n",
      "Exam_Priority                    0\n",
      "Weak_Subjects_Count              0\n",
      "Recommended_Hours_Per_Subject    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\astle\\Downloads\\study_plan_dataset.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head())\n",
    "print(df.isnull().sum())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c1cbad-6695-482c-a28b-07551e235181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "X = df.drop(columns=[\"Student_ID\", \"Recommended_Hours_Per_Subject\"])\n",
    "y = df[\"Recommended_Hours_Per_Subject\"]\n",
    "\n",
    "categorical_cols = [\"Learning_Style\", \"Exam_Priority\"]\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_cols),\n",
    "    (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), categorical_cols)\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afece270-3ac1-494e-9778-2f730d5c0457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(preprocessor, \"preprocessor.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cccbbeb-10e9-4ecc-bb31-ca0d4da6d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y.values, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18c71063-83cd-42da-ab76-26cf1dc81b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\astle\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\astle\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\astle\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\astle\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\astle\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2258725a-22db-4294-9563-f495a4881f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m3,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,385</span> (189.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,385\u001b[0m (189.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,489</span> (185.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,489\u001b[0m (185.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(256, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1, activation=\"linear\")\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"mse\",\n",
    "                  metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = build_model(input_dim)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bc9fd8c-3221-4d9d-a967-a7aa63f6435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.52599, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 3s - 116ms/step - loss: 0.9198 - mae: 0.7479 - val_loss: 0.5260 - val_mae: 0.5696 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 0.52599 to 0.47142, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 11ms/step - loss: 0.4685 - mae: 0.5392 - val_loss: 0.4714 - val_mae: 0.5155 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.47142 to 0.42496, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 14ms/step - loss: 0.3327 - mae: 0.4537 - val_loss: 0.4250 - val_mae: 0.4836 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.42496 to 0.34607, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 19ms/step - loss: 0.2636 - mae: 0.4006 - val_loss: 0.3461 - val_mae: 0.4224 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.34607 to 0.28392, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 11ms/step - loss: 0.2762 - mae: 0.4149 - val_loss: 0.2839 - val_mae: 0.3789 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.28392 to 0.26942, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 11ms/step - loss: 0.2435 - mae: 0.3847 - val_loss: 0.2694 - val_mae: 0.3697 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.26942 to 0.23244, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 12ms/step - loss: 0.2098 - mae: 0.3530 - val_loss: 0.2324 - val_mae: 0.3493 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss improved from 0.23244 to 0.18632, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 11ms/step - loss: 0.1707 - mae: 0.3237 - val_loss: 0.1863 - val_mae: 0.3090 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss improved from 0.18632 to 0.16654, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 13ms/step - loss: 0.1752 - mae: 0.3320 - val_loss: 0.1665 - val_mae: 0.2837 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss improved from 0.16654 to 0.16579, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 11ms/step - loss: 0.1590 - mae: 0.3140 - val_loss: 0.1658 - val_mae: 0.2868 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss improved from 0.16579 to 0.15149, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 10ms/step - loss: 0.1377 - mae: 0.2838 - val_loss: 0.1515 - val_mae: 0.2731 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.15149 to 0.12125, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 9ms/step - loss: 0.1320 - mae: 0.2827 - val_loss: 0.1213 - val_mae: 0.2409 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss improved from 0.12125 to 0.10871, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 9ms/step - loss: 0.1479 - mae: 0.3011 - val_loss: 0.1087 - val_mae: 0.2238 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss improved from 0.10871 to 0.09912, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 14ms/step - loss: 0.1284 - mae: 0.2755 - val_loss: 0.0991 - val_mae: 0.2173 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss improved from 0.09912 to 0.07242, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 16ms/step - loss: 0.1151 - mae: 0.2685 - val_loss: 0.0724 - val_mae: 0.1855 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.07242\n",
      "22/22 - 0s - 10ms/step - loss: 0.1124 - mae: 0.2619 - val_loss: 0.0764 - val_mae: 0.1950 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss improved from 0.07242 to 0.06923, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 12ms/step - loss: 0.0973 - mae: 0.2483 - val_loss: 0.0692 - val_mae: 0.1909 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss improved from 0.06923 to 0.04378, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 11ms/step - loss: 0.1003 - mae: 0.2515 - val_loss: 0.0438 - val_mae: 0.1491 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.04378\n",
      "22/22 - 0s - 7ms/step - loss: 0.0861 - mae: 0.2262 - val_loss: 0.0486 - val_mae: 0.1620 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.04378\n",
      "22/22 - 0s - 6ms/step - loss: 0.0887 - mae: 0.2364 - val_loss: 0.0464 - val_mae: 0.1651 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.04378\n",
      "22/22 - 0s - 5ms/step - loss: 0.0936 - mae: 0.2413 - val_loss: 0.0458 - val_mae: 0.1598 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss improved from 0.04378 to 0.03881, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 11ms/step - loss: 0.0790 - mae: 0.2179 - val_loss: 0.0388 - val_mae: 0.1507 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss improved from 0.03881 to 0.02435, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 12ms/step - loss: 0.0876 - mae: 0.2313 - val_loss: 0.0244 - val_mae: 0.1214 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.02435\n",
      "22/22 - 0s - 7ms/step - loss: 0.0762 - mae: 0.2134 - val_loss: 0.0298 - val_mae: 0.1330 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss improved from 0.02435 to 0.02092, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 13ms/step - loss: 0.0711 - mae: 0.2048 - val_loss: 0.0209 - val_mae: 0.1139 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.02092\n",
      "22/22 - 0s - 9ms/step - loss: 0.0765 - mae: 0.2124 - val_loss: 0.0236 - val_mae: 0.1212 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.02092\n",
      "22/22 - 0s - 5ms/step - loss: 0.0660 - mae: 0.1974 - val_loss: 0.0245 - val_mae: 0.1260 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss improved from 0.02092 to 0.02079, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 13ms/step - loss: 0.0612 - mae: 0.1938 - val_loss: 0.0208 - val_mae: 0.1167 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss improved from 0.02079 to 0.01811, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 15ms/step - loss: 0.0591 - mae: 0.1914 - val_loss: 0.0181 - val_mae: 0.1149 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01811\n",
      "22/22 - 0s - 16ms/step - loss: 0.0566 - mae: 0.1898 - val_loss: 0.0190 - val_mae: 0.1111 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss improved from 0.01811 to 0.01544, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 17ms/step - loss: 0.0596 - mae: 0.1866 - val_loss: 0.0154 - val_mae: 0.1026 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.01544\n",
      "22/22 - 0s - 13ms/step - loss: 0.0585 - mae: 0.1894 - val_loss: 0.0172 - val_mae: 0.1079 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.01544\n",
      "22/22 - 0s - 6ms/step - loss: 0.0603 - mae: 0.1936 - val_loss: 0.0188 - val_mae: 0.1128 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 34: val_loss improved from 0.01544 to 0.01352, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 9ms/step - loss: 0.0590 - mae: 0.1857 - val_loss: 0.0135 - val_mae: 0.0923 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.01352\n",
      "22/22 - 0s - 7ms/step - loss: 0.0489 - mae: 0.1730 - val_loss: 0.0167 - val_mae: 0.1001 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.01352\n",
      "22/22 - 0s - 7ms/step - loss: 0.0508 - mae: 0.1747 - val_loss: 0.0145 - val_mae: 0.0941 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.01352\n",
      "22/22 - 0s - 8ms/step - loss: 0.0529 - mae: 0.1732 - val_loss: 0.0149 - val_mae: 0.0972 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.01352\n",
      "22/22 - 0s - 10ms/step - loss: 0.0505 - mae: 0.1741 - val_loss: 0.0136 - val_mae: 0.0963 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.01352\n",
      "22/22 - 0s - 12ms/step - loss: 0.0516 - mae: 0.1763 - val_loss: 0.0185 - val_mae: 0.1066 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 40: val_loss improved from 0.01352 to 0.01105, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 15ms/step - loss: 0.0423 - mae: 0.1588 - val_loss: 0.0110 - val_mae: 0.0860 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.01105\n",
      "22/22 - 0s - 13ms/step - loss: 0.0527 - mae: 0.1770 - val_loss: 0.0125 - val_mae: 0.0909 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.01105\n",
      "22/22 - 0s - 9ms/step - loss: 0.0479 - mae: 0.1676 - val_loss: 0.0135 - val_mae: 0.0916 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.01105\n",
      "22/22 - 0s - 11ms/step - loss: 0.0434 - mae: 0.1587 - val_loss: 0.0135 - val_mae: 0.0923 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.01105\n",
      "22/22 - 0s - 6ms/step - loss: 0.0425 - mae: 0.1559 - val_loss: 0.0133 - val_mae: 0.0921 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.01105\n",
      "22/22 - 0s - 7ms/step - loss: 0.0414 - mae: 0.1568 - val_loss: 0.0111 - val_mae: 0.0831 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.01105\n",
      "22/22 - 0s - 7ms/step - loss: 0.0453 - mae: 0.1599 - val_loss: 0.0112 - val_mae: 0.0847 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.01105\n",
      "22/22 - 0s - 7ms/step - loss: 0.0400 - mae: 0.1521 - val_loss: 0.0113 - val_mae: 0.0838 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.01105\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "22/22 - 0s - 10ms/step - loss: 0.0443 - mae: 0.1604 - val_loss: 0.0118 - val_mae: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\n",
      "Epoch 49: val_loss improved from 0.01105 to 0.01053, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 13ms/step - loss: 0.0334 - mae: 0.1426 - val_loss: 0.0105 - val_mae: 0.0817 - learning_rate: 5.0000e-04\n",
      "Epoch 50/200\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.01053\n",
      "22/22 - 0s - 7ms/step - loss: 0.0380 - mae: 0.1495 - val_loss: 0.0122 - val_mae: 0.0861 - learning_rate: 5.0000e-04\n",
      "Epoch 51/200\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.01053\n",
      "22/22 - 0s - 6ms/step - loss: 0.0411 - mae: 0.1519 - val_loss: 0.0110 - val_mae: 0.0828 - learning_rate: 5.0000e-04\n",
      "Epoch 52/200\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.01053\n",
      "22/22 - 0s - 8ms/step - loss: 0.0326 - mae: 0.1389 - val_loss: 0.0108 - val_mae: 0.0811 - learning_rate: 5.0000e-04\n",
      "Epoch 53/200\n",
      "\n",
      "Epoch 53: val_loss improved from 0.01053 to 0.00991, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 13ms/step - loss: 0.0332 - mae: 0.1435 - val_loss: 0.0099 - val_mae: 0.0775 - learning_rate: 5.0000e-04\n",
      "Epoch 54/200\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00991\n",
      "22/22 - 0s - 10ms/step - loss: 0.0427 - mae: 0.1579 - val_loss: 0.0110 - val_mae: 0.0835 - learning_rate: 5.0000e-04\n",
      "Epoch 55/200\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00991\n",
      "22/22 - 0s - 5ms/step - loss: 0.0378 - mae: 0.1452 - val_loss: 0.0105 - val_mae: 0.0827 - learning_rate: 5.0000e-04\n",
      "Epoch 56/200\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00991\n",
      "22/22 - 0s - 6ms/step - loss: 0.0460 - mae: 0.1645 - val_loss: 0.0116 - val_mae: 0.0838 - learning_rate: 5.0000e-04\n",
      "Epoch 57/200\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00991\n",
      "22/22 - 0s - 6ms/step - loss: 0.0346 - mae: 0.1423 - val_loss: 0.0104 - val_mae: 0.0799 - learning_rate: 5.0000e-04\n",
      "Epoch 58/200\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00991\n",
      "22/22 - 0s - 5ms/step - loss: 0.0389 - mae: 0.1541 - val_loss: 0.0108 - val_mae: 0.0801 - learning_rate: 5.0000e-04\n",
      "Epoch 59/200\n",
      "\n",
      "Epoch 59: val_loss improved from 0.00991 to 0.00938, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 12ms/step - loss: 0.0331 - mae: 0.1386 - val_loss: 0.0094 - val_mae: 0.0753 - learning_rate: 5.0000e-04\n",
      "Epoch 60/200\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00938\n",
      "22/22 - 0s - 8ms/step - loss: 0.0346 - mae: 0.1390 - val_loss: 0.0096 - val_mae: 0.0768 - learning_rate: 5.0000e-04\n",
      "Epoch 61/200\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00938\n",
      "22/22 - 0s - 9ms/step - loss: 0.0347 - mae: 0.1413 - val_loss: 0.0136 - val_mae: 0.0901 - learning_rate: 5.0000e-04\n",
      "Epoch 62/200\n",
      "\n",
      "Epoch 62: val_loss improved from 0.00938 to 0.00849, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 12ms/step - loss: 0.0323 - mae: 0.1369 - val_loss: 0.0085 - val_mae: 0.0745 - learning_rate: 5.0000e-04\n",
      "Epoch 63/200\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 7ms/step - loss: 0.0360 - mae: 0.1430 - val_loss: 0.0103 - val_mae: 0.0807 - learning_rate: 5.0000e-04\n",
      "Epoch 64/200\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 6ms/step - loss: 0.0403 - mae: 0.1518 - val_loss: 0.0114 - val_mae: 0.0837 - learning_rate: 5.0000e-04\n",
      "Epoch 65/200\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 6ms/step - loss: 0.0314 - mae: 0.1338 - val_loss: 0.0099 - val_mae: 0.0790 - learning_rate: 5.0000e-04\n",
      "Epoch 66/200\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 7ms/step - loss: 0.0306 - mae: 0.1294 - val_loss: 0.0119 - val_mae: 0.0855 - learning_rate: 5.0000e-04\n",
      "Epoch 67/200\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 6ms/step - loss: 0.0376 - mae: 0.1484 - val_loss: 0.0117 - val_mae: 0.0829 - learning_rate: 5.0000e-04\n",
      "Epoch 68/200\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 7ms/step - loss: 0.0301 - mae: 0.1340 - val_loss: 0.0091 - val_mae: 0.0740 - learning_rate: 5.0000e-04\n",
      "Epoch 69/200\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 9ms/step - loss: 0.0346 - mae: 0.1398 - val_loss: 0.0096 - val_mae: 0.0758 - learning_rate: 5.0000e-04\n",
      "Epoch 70/200\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00849\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "22/22 - 0s - 6ms/step - loss: 0.0301 - mae: 0.1301 - val_loss: 0.0087 - val_mae: 0.0727 - learning_rate: 5.0000e-04\n",
      "Epoch 71/200\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 6ms/step - loss: 0.0329 - mae: 0.1385 - val_loss: 0.0090 - val_mae: 0.0747 - learning_rate: 2.5000e-04\n",
      "Epoch 72/200\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 8ms/step - loss: 0.0323 - mae: 0.1366 - val_loss: 0.0106 - val_mae: 0.0800 - learning_rate: 2.5000e-04\n",
      "Epoch 73/200\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00849\n",
      "22/22 - 0s - 5ms/step - loss: 0.0346 - mae: 0.1391 - val_loss: 0.0107 - val_mae: 0.0800 - learning_rate: 2.5000e-04\n",
      "Epoch 74/200\n",
      "\n",
      "Epoch 74: val_loss improved from 0.00849 to 0.00820, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 9ms/step - loss: 0.0340 - mae: 0.1388 - val_loss: 0.0082 - val_mae: 0.0711 - learning_rate: 2.5000e-04\n",
      "Epoch 75/200\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00820\n",
      "22/22 - 0s - 7ms/step - loss: 0.0365 - mae: 0.1426 - val_loss: 0.0099 - val_mae: 0.0751 - learning_rate: 2.5000e-04\n",
      "Epoch 76/200\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00820\n",
      "22/22 - 0s - 8ms/step - loss: 0.0353 - mae: 0.1396 - val_loss: 0.0114 - val_mae: 0.0808 - learning_rate: 2.5000e-04\n",
      "Epoch 77/200\n",
      "\n",
      "Epoch 77: val_loss improved from 0.00820 to 0.00797, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 12ms/step - loss: 0.0344 - mae: 0.1354 - val_loss: 0.0080 - val_mae: 0.0696 - learning_rate: 2.5000e-04\n",
      "Epoch 78/200\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0287 - mae: 0.1267 - val_loss: 0.0102 - val_mae: 0.0769 - learning_rate: 2.5000e-04\n",
      "Epoch 79/200\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0346 - mae: 0.1383 - val_loss: 0.0099 - val_mae: 0.0758 - learning_rate: 2.5000e-04\n",
      "Epoch 80/200\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0308 - mae: 0.1315 - val_loss: 0.0101 - val_mae: 0.0764 - learning_rate: 2.5000e-04\n",
      "Epoch 81/200\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0300 - mae: 0.1328 - val_loss: 0.0094 - val_mae: 0.0735 - learning_rate: 2.5000e-04\n",
      "Epoch 82/200\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0339 - mae: 0.1385 - val_loss: 0.0107 - val_mae: 0.0772 - learning_rate: 2.5000e-04\n",
      "Epoch 83/200\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 8ms/step - loss: 0.0313 - mae: 0.1387 - val_loss: 0.0089 - val_mae: 0.0728 - learning_rate: 2.5000e-04\n",
      "Epoch 84/200\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 11ms/step - loss: 0.0271 - mae: 0.1282 - val_loss: 0.0101 - val_mae: 0.0780 - learning_rate: 2.5000e-04\n",
      "Epoch 85/200\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00797\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "22/22 - 0s - 7ms/step - loss: 0.0318 - mae: 0.1320 - val_loss: 0.0094 - val_mae: 0.0746 - learning_rate: 2.5000e-04\n",
      "Epoch 86/200\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0319 - mae: 0.1328 - val_loss: 0.0082 - val_mae: 0.0700 - learning_rate: 1.2500e-04\n",
      "Epoch 87/200\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0307 - mae: 0.1305 - val_loss: 0.0083 - val_mae: 0.0705 - learning_rate: 1.2500e-04\n",
      "Epoch 88/200\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 9ms/step - loss: 0.0267 - mae: 0.1224 - val_loss: 0.0092 - val_mae: 0.0738 - learning_rate: 1.2500e-04\n",
      "Epoch 89/200\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 9ms/step - loss: 0.0349 - mae: 0.1358 - val_loss: 0.0084 - val_mae: 0.0712 - learning_rate: 1.2500e-04\n",
      "Epoch 90/200\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 8ms/step - loss: 0.0309 - mae: 0.1349 - val_loss: 0.0086 - val_mae: 0.0717 - learning_rate: 1.2500e-04\n",
      "Epoch 91/200\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 9ms/step - loss: 0.0358 - mae: 0.1441 - val_loss: 0.0099 - val_mae: 0.0773 - learning_rate: 1.2500e-04\n",
      "Epoch 92/200\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 8ms/step - loss: 0.0311 - mae: 0.1305 - val_loss: 0.0090 - val_mae: 0.0737 - learning_rate: 1.2500e-04\n",
      "Epoch 93/200\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00797\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "22/22 - 0s - 7ms/step - loss: 0.0321 - mae: 0.1318 - val_loss: 0.0096 - val_mae: 0.0761 - learning_rate: 1.2500e-04\n",
      "Epoch 94/200\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0398 - mae: 0.1481 - val_loss: 0.0093 - val_mae: 0.0746 - learning_rate: 6.2500e-05\n",
      "Epoch 95/200\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0326 - mae: 0.1357 - val_loss: 0.0089 - val_mae: 0.0726 - learning_rate: 6.2500e-05\n",
      "Epoch 96/200\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 7ms/step - loss: 0.0273 - mae: 0.1245 - val_loss: 0.0093 - val_mae: 0.0745 - learning_rate: 6.2500e-05\n",
      "Epoch 97/200\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00797\n",
      "22/22 - 0s - 9ms/step - loss: 0.0257 - mae: 0.1230 - val_loss: 0.0092 - val_mae: 0.0740 - learning_rate: 6.2500e-05\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint(\"study_plan_model.h5\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=8, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.15,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b884c49-e053-41d5-a721-f01c192319a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "MSE=0.0076, MAE=0.0656, R2=0.9514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MSE={mse:.4f}, MAE={mae:.4f}, R2={r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4ebb587-39de-4327-8c01-13fac0ecdd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['preprocessor.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"study_plan_model.h5\")  \n",
    "joblib.dump(preprocessor, \"preprocessor.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0bbbd89-d9a1-456a-899a-22699b47dc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "Predicted hours per subject: 1.01\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "preprocessor = joblib.load(\"preprocessor.joblib\")\n",
    "model = load_model(\"study_plan_model.h5\", compile=False)\n",
    "new_student = pd.DataFrame([{\n",
    "    \"GPA\": 8.2,\n",
    "    \"Learning_Style\": \"Visual\",\n",
    "    \"Available_Hours_Per_Day\": 5,\n",
    "    \"Free_Days_Per_Week\": 6,\n",
    "    \"Subject_Count\": 6,\n",
    "    \"Exam_Priority\": \"High\",\n",
    "    \"Weak_Subjects_Count\": 2\n",
    "}])\n",
    "X_new = preprocessor.transform(new_student)\n",
    "predicted_hours = model.predict(X_new).flatten()[0]\n",
    "print(\"Predicted hours per subject:\", round(predicted_hours, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3d0dc0-5c3c-46e5-8701-9b0c2d248992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Day  Hours\n",
       "0   Monday   15.0\n",
       "1  Tuesday   15.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Math</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Physics</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monday</td>\n",
       "      <td>CS</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monday</td>\n",
       "      <td>English</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Biology</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Math</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Physics</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>CS</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>English</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Biology</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Day    Subject  Hours\n",
       "0    Monday       Math    2.5\n",
       "1    Monday    Physics    3.5\n",
       "2    Monday         CS    4.0\n",
       "3    Monday  Chemistry    2.0\n",
       "4    Monday    English    1.0\n",
       "5    Monday    Biology    2.0\n",
       "6   Tuesday       Math    2.5\n",
       "7   Tuesday    Physics    3.5\n",
       "8   Tuesday         CS    4.0\n",
       "9   Tuesday  Chemistry    2.0\n",
       "10  Tuesday    English    1.0\n",
       "11  Tuesday    Biology    2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def generate_weekly_schedule(predicted_hours_per_subject, subject_names, available_hours_per_day, \n",
    "                            free_days_per_week, weak_subjects, weak_extra=0.5, session_granularity=0.5):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    study_days = days[:(7-free_days_per_week)]\n",
    "    rows = []\n",
    "    for day in study_days:\n",
    "        for subject, hours in zip(subject_names, predicted_hours_per_subject):\n",
    "            # Add extra time for weak subjects\n",
    "            if isinstance(weak_subjects, int) and subject_names.index(subject) < weak_subjects:\n",
    "                hours += weak_extra\n",
    "            elif isinstance(weak_subjects, list) and subject in weak_subjects:\n",
    "                hours += weak_extra\n",
    "            hours = round(hours / session_granularity) * session_granularity\n",
    "            \n",
    "            rows.append({\n",
    "                'Day': day,\n",
    "                'Subject': subject,\n",
    "                'Hours': hours\n",
    "            })\n",
    "    \n",
    "    df_detail = pd.DataFrame(rows)\n",
    "    df_summary = df_detail.groupby('Day').agg({'Hours': 'sum'}).reset_index()\n",
    "    total_hours = df_detail['Hours'].sum()\n",
    "    target_hours = sum(predicted_hours_per_subject) * len(study_days)\n",
    "    remaining = target_hours - total_hours\n",
    "    \n",
    "    return df_detail, df_summary, remaining, target_hours\n",
    "new_student = pd.DataFrame({\n",
    "    \"Available_Hours_Per_Day\": [4],  \n",
    "    \"Free_Days_Per_Week\": [5],       \n",
    "    \"Weak_Subjects_Count\": [2]       \n",
    "})\n",
    "predicted_hours = [2, 3, 4, 2, 1, 2]  \n",
    "subject_names = [\"Math\",\"Physics\",\"CS\",\"Chemistry\",\"English\",\"Biology\"]  \n",
    "available_hours_per_day = int(new_student.loc[0, \"Available_Hours_Per_Day\"])\n",
    "free_days_per_week = int(new_student.loc[0, \"Free_Days_Per_Week\"])\n",
    "weak_subjects = int(new_student.loc[0, \"Weak_Subjects_Count\"])  \n",
    "\n",
    "df_detail, df_summary, remaining, target_hours = generate_weekly_schedule(\n",
    "    predicted_hours_per_subject=predicted_hours,\n",
    "    subject_names=subject_names,\n",
    "    available_hours_per_day=available_hours_per_day,\n",
    "    free_days_per_week=free_days_per_week,\n",
    "    weak_subjects=weak_subjects,\n",
    "    weak_extra=0.5,            \n",
    "    session_granularity=0.5    \n",
    ")\n",
    "\n",
    "display(df_summary)   \n",
    "display(df_detail)    \n",
    "\n",
    "df_summary.to_csv(\"weekly_schedule_summary.csv\", index=False)\n",
    "df_detail.to_csv(\"weekly_schedule_detailed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85143900-86f8-4ed9-85dd-ccc8c7e145f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astle\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.72472, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 7s - 326ms/step - loss: 0.8217 - mae: 0.6948 - val_loss: 0.7247 - val_mae: 0.7175 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 0.72472 to 0.45925, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 26ms/step - loss: 0.5093 - mae: 0.5603 - val_loss: 0.4592 - val_mae: 0.5091 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 0.45925 to 0.31152, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 23ms/step - loss: 0.3476 - mae: 0.4659 - val_loss: 0.3115 - val_mae: 0.3853 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 0.31152 to 0.22546, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 28ms/step - loss: 0.2627 - mae: 0.3999 - val_loss: 0.2255 - val_mae: 0.3275 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 0.22546 to 0.18981, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 29ms/step - loss: 0.2561 - mae: 0.3868 - val_loss: 0.1898 - val_mae: 0.3050 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 0.18981 to 0.16612, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 31ms/step - loss: 0.1933 - mae: 0.3370 - val_loss: 0.1661 - val_mae: 0.2961 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 0.16612 to 0.13010, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 28ms/step - loss: 0.1780 - mae: 0.3344 - val_loss: 0.1301 - val_mae: 0.2574 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss improved from 0.13010 to 0.11046, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 30ms/step - loss: 0.1692 - mae: 0.3213 - val_loss: 0.1105 - val_mae: 0.2432 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss improved from 0.11046 to 0.10053, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 32ms/step - loss: 0.1654 - mae: 0.3192 - val_loss: 0.1005 - val_mae: 0.2359 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss improved from 0.10053 to 0.09023, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 22ms/step - loss: 0.1510 - mae: 0.3053 - val_loss: 0.0902 - val_mae: 0.2214 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.09023\n",
      "22/22 - 0s - 22ms/step - loss: 0.1479 - mae: 0.3018 - val_loss: 0.0979 - val_mae: 0.2268 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss improved from 0.09023 to 0.07718, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 22ms/step - loss: 0.1290 - mae: 0.2815 - val_loss: 0.0772 - val_mae: 0.2032 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.07718\n",
      "22/22 - 1s - 26ms/step - loss: 0.1160 - mae: 0.2628 - val_loss: 0.0799 - val_mae: 0.2021 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss improved from 0.07718 to 0.07422, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 22ms/step - loss: 0.1206 - mae: 0.2651 - val_loss: 0.0742 - val_mae: 0.1964 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss improved from 0.07422 to 0.06607, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 28ms/step - loss: 0.1209 - mae: 0.2722 - val_loss: 0.0661 - val_mae: 0.1821 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss improved from 0.06607 to 0.05830, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 29ms/step - loss: 0.1135 - mae: 0.2629 - val_loss: 0.0583 - val_mae: 0.1725 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss improved from 0.05830 to 0.04830, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 27ms/step - loss: 0.0970 - mae: 0.2397 - val_loss: 0.0483 - val_mae: 0.1589 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss improved from 0.04830 to 0.04667, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 22ms/step - loss: 0.0817 - mae: 0.2241 - val_loss: 0.0467 - val_mae: 0.1611 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss improved from 0.04667 to 0.04628, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 32ms/step - loss: 0.0820 - mae: 0.2248 - val_loss: 0.0463 - val_mae: 0.1562 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss improved from 0.04628 to 0.03032, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 27ms/step - loss: 0.0800 - mae: 0.2201 - val_loss: 0.0303 - val_mae: 0.1349 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.03032\n",
      "22/22 - 1s - 24ms/step - loss: 0.0783 - mae: 0.2187 - val_loss: 0.0339 - val_mae: 0.1394 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.03032\n",
      "22/22 - 0s - 15ms/step - loss: 0.0705 - mae: 0.2111 - val_loss: 0.0319 - val_mae: 0.1359 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.03032\n",
      "22/22 - 0s - 16ms/step - loss: 0.0864 - mae: 0.2291 - val_loss: 0.0330 - val_mae: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss improved from 0.03032 to 0.02737, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 36ms/step - loss: 0.0665 - mae: 0.2063 - val_loss: 0.0274 - val_mae: 0.1261 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.02737\n",
      "22/22 - 1s - 24ms/step - loss: 0.0624 - mae: 0.1919 - val_loss: 0.0297 - val_mae: 0.1265 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss improved from 0.02737 to 0.02699, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 21ms/step - loss: 0.0636 - mae: 0.1935 - val_loss: 0.0270 - val_mae: 0.1251 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.02699\n",
      "22/22 - 0s - 16ms/step - loss: 0.0618 - mae: 0.1902 - val_loss: 0.0307 - val_mae: 0.1342 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.02699\n",
      "22/22 - 1s - 28ms/step - loss: 0.0596 - mae: 0.1914 - val_loss: 0.0275 - val_mae: 0.1282 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss improved from 0.02699 to 0.02339, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 35ms/step - loss: 0.0568 - mae: 0.1850 - val_loss: 0.0234 - val_mae: 0.1185 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.02339\n",
      "22/22 - 1s - 25ms/step - loss: 0.0618 - mae: 0.1895 - val_loss: 0.0276 - val_mae: 0.1307 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss improved from 0.02339 to 0.02320, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 38ms/step - loss: 0.0596 - mae: 0.1850 - val_loss: 0.0232 - val_mae: 0.1193 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.02320\n",
      "22/22 - 1s - 23ms/step - loss: 0.0504 - mae: 0.1748 - val_loss: 0.0271 - val_mae: 0.1301 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.02320\n",
      "22/22 - 0s - 17ms/step - loss: 0.0500 - mae: 0.1701 - val_loss: 0.0265 - val_mae: 0.1299 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 34: val_loss improved from 0.02320 to 0.01975, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 30ms/step - loss: 0.0503 - mae: 0.1741 - val_loss: 0.0197 - val_mae: 0.1091 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.01975\n",
      "22/22 - 1s - 47ms/step - loss: 0.0512 - mae: 0.1762 - val_loss: 0.0249 - val_mae: 0.1254 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 36: val_loss improved from 0.01975 to 0.01917, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 35ms/step - loss: 0.0450 - mae: 0.1647 - val_loss: 0.0192 - val_mae: 0.1080 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.01917\n",
      "22/22 - 1s - 23ms/step - loss: 0.0496 - mae: 0.1704 - val_loss: 0.0209 - val_mae: 0.1097 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 38: val_loss improved from 0.01917 to 0.01866, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 35ms/step - loss: 0.0417 - mae: 0.1596 - val_loss: 0.0187 - val_mae: 0.1078 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.01866\n",
      "22/22 - 1s - 24ms/step - loss: 0.0500 - mae: 0.1740 - val_loss: 0.0188 - val_mae: 0.1031 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 40: val_loss improved from 0.01866 to 0.01703, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 22ms/step - loss: 0.0501 - mae: 0.1704 - val_loss: 0.0170 - val_mae: 0.1002 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 41: val_loss improved from 0.01703 to 0.01336, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 22ms/step - loss: 0.0565 - mae: 0.1793 - val_loss: 0.0134 - val_mae: 0.0873 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.01336\n",
      "22/22 - 0s - 22ms/step - loss: 0.0448 - mae: 0.1616 - val_loss: 0.0250 - val_mae: 0.1180 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 43: val_loss improved from 0.01336 to 0.01204, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 39ms/step - loss: 0.0515 - mae: 0.1688 - val_loss: 0.0120 - val_mae: 0.0847 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.01204\n",
      "22/22 - 0s - 19ms/step - loss: 0.0500 - mae: 0.1697 - val_loss: 0.0228 - val_mae: 0.1076 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.01204\n",
      "22/22 - 1s - 29ms/step - loss: 0.0416 - mae: 0.1553 - val_loss: 0.0137 - val_mae: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.01204\n",
      "22/22 - 0s - 16ms/step - loss: 0.0392 - mae: 0.1505 - val_loss: 0.0131 - val_mae: 0.0872 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.01204\n",
      "22/22 - 1s - 29ms/step - loss: 0.0412 - mae: 0.1545 - val_loss: 0.0143 - val_mae: 0.0939 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.01204\n",
      "22/22 - 1s - 29ms/step - loss: 0.0390 - mae: 0.1501 - val_loss: 0.0131 - val_mae: 0.0808 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.01204\n",
      "22/22 - 1s - 30ms/step - loss: 0.0371 - mae: 0.1428 - val_loss: 0.0122 - val_mae: 0.0842 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.01204\n",
      "22/22 - 0s - 17ms/step - loss: 0.0346 - mae: 0.1417 - val_loss: 0.0143 - val_mae: 0.0893 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\n",
      "Epoch 51: val_loss improved from 0.01204 to 0.00888, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 34ms/step - loss: 0.0288 - mae: 0.1317 - val_loss: 0.0089 - val_mae: 0.0716 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00888\n",
      "22/22 - 1s - 25ms/step - loss: 0.0335 - mae: 0.1437 - val_loss: 0.0149 - val_mae: 0.0853 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00888\n",
      "22/22 - 0s - 15ms/step - loss: 0.0354 - mae: 0.1404 - val_loss: 0.0109 - val_mae: 0.0795 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00888\n",
      "22/22 - 0s - 16ms/step - loss: 0.0384 - mae: 0.1470 - val_loss: 0.0218 - val_mae: 0.0973 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00888\n",
      "22/22 - 1s - 29ms/step - loss: 0.0354 - mae: 0.1403 - val_loss: 0.0113 - val_mae: 0.0814 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00888\n",
      "22/22 - 0s - 15ms/step - loss: 0.0333 - mae: 0.1369 - val_loss: 0.0101 - val_mae: 0.0763 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00888\n",
      "22/22 - 1s - 28ms/step - loss: 0.0348 - mae: 0.1399 - val_loss: 0.0089 - val_mae: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00888\n",
      "22/22 - 0s - 15ms/step - loss: 0.0289 - mae: 0.1310 - val_loss: 0.0102 - val_mae: 0.0774 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00888\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "22/22 - 1s - 29ms/step - loss: 0.0313 - mae: 0.1340 - val_loss: 0.0106 - val_mae: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00888\n",
      "22/22 - 0s - 15ms/step - loss: 0.0331 - mae: 0.1407 - val_loss: 0.0108 - val_mae: 0.0814 - learning_rate: 5.0000e-04\n",
      "Epoch 61/200\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00888\n",
      "22/22 - 1s - 28ms/step - loss: 0.0291 - mae: 0.1290 - val_loss: 0.0090 - val_mae: 0.0748 - learning_rate: 5.0000e-04\n",
      "Epoch 62/200\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00888\n",
      "22/22 - 0s - 16ms/step - loss: 0.0307 - mae: 0.1287 - val_loss: 0.0100 - val_mae: 0.0787 - learning_rate: 5.0000e-04\n",
      "Epoch 63/200\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00888\n",
      "22/22 - 1s - 33ms/step - loss: 0.0348 - mae: 0.1391 - val_loss: 0.0100 - val_mae: 0.0782 - learning_rate: 5.0000e-04\n",
      "Epoch 64/200\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00888\n",
      "22/22 - 1s - 26ms/step - loss: 0.0346 - mae: 0.1391 - val_loss: 0.0108 - val_mae: 0.0805 - learning_rate: 5.0000e-04\n",
      "Epoch 65/200\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00888\n",
      "22/22 - 1s - 29ms/step - loss: 0.0257 - mae: 0.1210 - val_loss: 0.0108 - val_mae: 0.0792 - learning_rate: 5.0000e-04\n",
      "Epoch 66/200\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00888\n",
      "22/22 - 0s - 15ms/step - loss: 0.0322 - mae: 0.1336 - val_loss: 0.0109 - val_mae: 0.0804 - learning_rate: 5.0000e-04\n",
      "Epoch 67/200\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00888\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "22/22 - 0s - 17ms/step - loss: 0.0269 - mae: 0.1246 - val_loss: 0.0106 - val_mae: 0.0796 - learning_rate: 5.0000e-04\n",
      "Epoch 68/200\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00888\n",
      "22/22 - 1s - 26ms/step - loss: 0.0278 - mae: 0.1248 - val_loss: 0.0116 - val_mae: 0.0832 - learning_rate: 2.5000e-04\n",
      "Epoch 69/200\n",
      "\n",
      "Epoch 69: val_loss improved from 0.00888 to 0.00821, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - 22ms/step - loss: 0.0274 - mae: 0.1251 - val_loss: 0.0082 - val_mae: 0.0716 - learning_rate: 2.5000e-04\n",
      "Epoch 70/200\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00821\n",
      "22/22 - 1s - 25ms/step - loss: 0.0296 - mae: 0.1327 - val_loss: 0.0098 - val_mae: 0.0769 - learning_rate: 2.5000e-04\n",
      "Epoch 71/200\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00821\n",
      "22/22 - 0s - 15ms/step - loss: 0.0296 - mae: 0.1269 - val_loss: 0.0117 - val_mae: 0.0808 - learning_rate: 2.5000e-04\n",
      "Epoch 72/200\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00821\n",
      "22/22 - 1s - 29ms/step - loss: 0.0272 - mae: 0.1238 - val_loss: 0.0091 - val_mae: 0.0742 - learning_rate: 2.5000e-04\n",
      "Epoch 73/200\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00821\n",
      "22/22 - 0s - 17ms/step - loss: 0.0314 - mae: 0.1318 - val_loss: 0.0116 - val_mae: 0.0815 - learning_rate: 2.5000e-04\n",
      "Epoch 74/200\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00821\n",
      "22/22 - 0s - 17ms/step - loss: 0.0334 - mae: 0.1349 - val_loss: 0.0094 - val_mae: 0.0758 - learning_rate: 2.5000e-04\n",
      "Epoch 75/200\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00821\n",
      "22/22 - 1s - 27ms/step - loss: 0.0260 - mae: 0.1224 - val_loss: 0.0089 - val_mae: 0.0748 - learning_rate: 2.5000e-04\n",
      "Epoch 76/200\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00821\n",
      "22/22 - 0s - 14ms/step - loss: 0.0322 - mae: 0.1359 - val_loss: 0.0107 - val_mae: 0.0799 - learning_rate: 2.5000e-04\n",
      "Epoch 77/200\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00821\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "22/22 - 0s - 17ms/step - loss: 0.0277 - mae: 0.1246 - val_loss: 0.0093 - val_mae: 0.0765 - learning_rate: 2.5000e-04\n",
      "Epoch 78/200\n",
      "\n",
      "Epoch 78: val_loss improved from 0.00821 to 0.00818, saving model to study_plan_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 1s - 36ms/step - loss: 0.0294 - mae: 0.1274 - val_loss: 0.0082 - val_mae: 0.0714 - learning_rate: 1.2500e-04\n",
      "Epoch 79/200\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00818\n",
      "22/22 - 1s - 23ms/step - loss: 0.0298 - mae: 0.1305 - val_loss: 0.0092 - val_mae: 0.0742 - learning_rate: 1.2500e-04\n",
      "Epoch 80/200\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00818\n",
      "22/22 - 1s - 30ms/step - loss: 0.0286 - mae: 0.1294 - val_loss: 0.0089 - val_mae: 0.0726 - learning_rate: 1.2500e-04\n",
      "Epoch 81/200\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00818\n",
      "22/22 - 1s - 32ms/step - loss: 0.0290 - mae: 0.1291 - val_loss: 0.0093 - val_mae: 0.0740 - learning_rate: 1.2500e-04\n",
      "Epoch 82/200\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00818\n",
      "22/22 - 1s - 29ms/step - loss: 0.0310 - mae: 0.1307 - val_loss: 0.0088 - val_mae: 0.0725 - learning_rate: 1.2500e-04\n",
      "Epoch 83/200\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 18ms/step - loss: 0.0312 - mae: 0.1318 - val_loss: 0.0098 - val_mae: 0.0760 - learning_rate: 1.2500e-04\n",
      "Epoch 84/200\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00818\n",
      "22/22 - 1s - 30ms/step - loss: 0.0295 - mae: 0.1306 - val_loss: 0.0095 - val_mae: 0.0751 - learning_rate: 1.2500e-04\n",
      "Epoch 85/200\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00818\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "22/22 - 0s - 16ms/step - loss: 0.0261 - mae: 0.1216 - val_loss: 0.0099 - val_mae: 0.0770 - learning_rate: 1.2500e-04\n",
      "Epoch 86/200\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 18ms/step - loss: 0.0238 - mae: 0.1172 - val_loss: 0.0097 - val_mae: 0.0760 - learning_rate: 6.2500e-05\n",
      "Epoch 87/200\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 15ms/step - loss: 0.0264 - mae: 0.1196 - val_loss: 0.0094 - val_mae: 0.0752 - learning_rate: 6.2500e-05\n",
      "Epoch 88/200\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 14ms/step - loss: 0.0297 - mae: 0.1265 - val_loss: 0.0091 - val_mae: 0.0739 - learning_rate: 6.2500e-05\n",
      "Epoch 89/200\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 15ms/step - loss: 0.0307 - mae: 0.1268 - val_loss: 0.0099 - val_mae: 0.0758 - learning_rate: 6.2500e-05\n",
      "Epoch 90/200\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 15ms/step - loss: 0.0314 - mae: 0.1312 - val_loss: 0.0096 - val_mae: 0.0753 - learning_rate: 6.2500e-05\n",
      "Epoch 91/200\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 14ms/step - loss: 0.0330 - mae: 0.1342 - val_loss: 0.0097 - val_mae: 0.0754 - learning_rate: 6.2500e-05\n",
      "Epoch 92/200\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 16ms/step - loss: 0.0322 - mae: 0.1320 - val_loss: 0.0098 - val_mae: 0.0761 - learning_rate: 6.2500e-05\n",
      "Epoch 93/200\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00818\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "22/22 - 0s - 15ms/step - loss: 0.0276 - mae: 0.1215 - val_loss: 0.0091 - val_mae: 0.0744 - learning_rate: 6.2500e-05\n",
      "Epoch 94/200\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 15ms/step - loss: 0.0304 - mae: 0.1240 - val_loss: 0.0086 - val_mae: 0.0726 - learning_rate: 3.1250e-05\n",
      "Epoch 95/200\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 16ms/step - loss: 0.0254 - mae: 0.1222 - val_loss: 0.0087 - val_mae: 0.0727 - learning_rate: 3.1250e-05\n",
      "Epoch 96/200\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 15ms/step - loss: 0.0275 - mae: 0.1254 - val_loss: 0.0089 - val_mae: 0.0730 - learning_rate: 3.1250e-05\n",
      "Epoch 97/200\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 14ms/step - loss: 0.0290 - mae: 0.1269 - val_loss: 0.0092 - val_mae: 0.0740 - learning_rate: 3.1250e-05\n",
      "Epoch 98/200\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00818\n",
      "22/22 - 0s - 14ms/step - loss: 0.0282 - mae: 0.1299 - val_loss: 0.0088 - val_mae: 0.0731 - learning_rate: 3.1250e-05\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\astle\\Downloads\\study_plan_dataset.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Student_ID\", \"Recommended_Hours_Per_Subject\"])\n",
    "y = df[\"Recommended_Hours_Per_Subject\"]\n",
    "\n",
    "categorical_cols = [\"Learning_Style\", \"Exam_Priority\"]\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_cols),\n",
    "    (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), categorical_cols)\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "joblib.dump(preprocessor, \"preprocessor.joblib\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y.values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(256, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1, activation=\"linear\")\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"mse\",\n",
    "                  metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = build_model(input_dim)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint(\"study_plan_model.h5\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=8, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.15,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "model.save(\"study_plan_model.h5\")\n",
    "joblib.dump(preprocessor, \"preprocessor.joblib\")\n",
    "\n",
    "preprocessor = joblib.load(\"preprocessor.joblib\")\n",
    "model = load_model(\"study_plan_model.h5\", compile=False)\n",
    "\n",
    "new_student = pd.DataFrame([{\n",
    "    \"GPA\": 8.2,\n",
    "    \"Learning_Style\": \"Visual\",\n",
    "    \"Available_Hours_Per_Day\": 5,\n",
    "    \"Free_Days_Per_Week\": 6,\n",
    "    \"Subject_Count\": 6,\n",
    "    \"Exam_Priority\": \"High\",\n",
    "    \"Weak_Subjects_Count\": 2\n",
    "}])\n",
    "\n",
    "X_new = preprocessor.transform(new_student)\n",
    "predicted_hours = model.predict(X_new).flatten()[0]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def generate_weekly_schedule(predicted_hours_per_subject, subject_names, available_hours_per_day, \n",
    "                            free_days_per_week, weak_subjects, weak_extra=0.5, session_granularity=0.5):\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    study_days = days[:(7-free_days_per_week)]\n",
    "    rows = []\n",
    "    for day in study_days:\n",
    "        for subject, hours in zip(subject_names, predicted_hours_per_subject):\n",
    "            if isinstance(weak_subjects, int) and subject_names.index(subject) < weak_subjects:\n",
    "                hours += weak_extra\n",
    "            elif isinstance(weak_subjects, list) and subject in weak_subjects:\n",
    "                hours += weak_extra\n",
    "            hours = round(hours / session_granularity) * session_granularity\n",
    "            rows.append({'Day': day, 'Subject': subject, 'Hours': hours})\n",
    "    df_detail = pd.DataFrame(rows)\n",
    "    df_summary = df_detail.groupby('Day').agg({'Hours': 'sum'}).reset_index()\n",
    "    total_hours = df_detail['Hours'].sum()\n",
    "    target_hours = sum(predicted_hours_per_subject) * len(study_days)\n",
    "    remaining = target_hours - total_hours\n",
    "    return df_detail, df_summary, remaining, target_hours\n",
    "\n",
    "new_student = pd.DataFrame({\n",
    "    \"Available_Hours_Per_Day\": [4],\n",
    "    \"Free_Days_Per_Week\": [5],\n",
    "    \"Weak_Subjects_Count\": [2]\n",
    "})\n",
    "\n",
    "predicted_hours = [2, 3, 4, 2, 1, 2]\n",
    "subject_names = [\"Math\", \"Physics\", \"CS\", \"Chemistry\", \"English\", \"Biology\"]\n",
    "available_hours_per_day = int(new_student.loc[0, \"Available_Hours_Per_Day\"])\n",
    "free_days_per_week = int(new_student.loc[0, \"Free_Days_Per_Week\"])\n",
    "weak_subjects = int(new_student.loc[0, \"Weak_Subjects_Count\"])\n",
    "\n",
    "df_detail, df_summary, remaining, target_hours = generate_weekly_schedule(\n",
    "    predicted_hours_per_subject=predicted_hours,\n",
    "    subject_names=subject_names,\n",
    "    available_hours_per_day=available_hours_per_day,\n",
    "    free_days_per_week=free_days_per_week,\n",
    "    weak_subjects=weak_subjects,\n",
    "    weak_extra=0.5,\n",
    "    session_granularity=0.5\n",
    ")\n",
    "\n",
    "df_summary.to_csv(\"weekly_schedule_summary.csv\", index=False)\n",
    "df_detail.to_csv(\"weekly_schedule_detailed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e133d0-c504-427a-8f92-de2c72044619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
