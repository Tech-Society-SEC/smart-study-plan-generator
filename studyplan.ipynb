import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib

df = pd.read_csv(r"C:\Users\astle\Downloads\study_plan_dataset.csv")

X = df.drop(columns=["Student_ID", "Recommended_Hours_Per_Subject"])
y = df["Recommended_Hours_Per_Subject"]

categorical_cols = ["Learning_Style", "Exam_Priority"]
numeric_cols = [c for c in X.columns if c not in categorical_cols]

preprocessor = ColumnTransformer([
    ("num", StandardScaler(), numeric_cols),
    ("cat", OneHotEncoder(sparse_output=False, handle_unknown="ignore"), categorical_cols)
])

X_processed = preprocessor.fit_transform(X)
joblib.dump(preprocessor, "preprocessor.joblib")

X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y.values, test_size=0.2, random_state=42
)

def build_model(input_dim):
    model = Sequential([
        Dense(256, activation="relu", input_shape=(input_dim,)),
        BatchNormalization(),
        Dropout(0.3),
        Dense(128, activation="relu"),
        BatchNormalization(),
        Dropout(0.25),
        Dense(64, activation="relu"),
        BatchNormalization(),
        Dropout(0.2),
        Dense(32, activation="relu"),
        Dense(1, activation="linear")
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
                  loss="mse",
                  metrics=["mae"])
    return model

input_dim = X_train.shape[1]
model = build_model(input_dim)

callbacks = [
    EarlyStopping(monitor="val_loss", patience=20, restore_best_weights=True, verbose=1),
    ModelCheckpoint("study_plan_model.h5", save_best_only=True, monitor="val_loss", verbose=1),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=8, verbose=1)
]

history = model.fit(
    X_train, y_train,
    validation_split=0.15,
    epochs=200,
    batch_size=32,
    callbacks=callbacks,
    verbose=2
)

y_pred = model.predict(X_test).flatten()
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

model.save("study_plan_model.h5")
joblib.dump(preprocessor, "preprocessor.joblib")

preprocessor = joblib.load("preprocessor.joblib")
model = load_model("study_plan_model.h5", compile=False)

new_student = pd.DataFrame([{
    "GPA": 8.2,
    "Learning_Style": "Visual",
    "Available_Hours_Per_Day": 5,
    "Free_Days_Per_Week": 6,
    "Subject_Count": 6,
    "Exam_Priority": "High",
    "Weak_Subjects_Count": 2
}])

X_new = preprocessor.transform(new_student)
predicted_hours = model.predict(X_new).flatten()[0]

import numpy as np

def generate_weekly_schedule(predicted_hours_per_subject, subject_names, available_hours_per_day, 
                            free_days_per_week, weak_subjects, weak_extra=0.5, session_granularity=0.5):
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    study_days = days[:(7-free_days_per_week)]
    rows = []
    for day in study_days:
        for subject, hours in zip(subject_names, predicted_hours_per_subject):
            if isinstance(weak_subjects, int) and subject_names.index(subject) < weak_subjects:
                hours += weak_extra
            elif isinstance(weak_subjects, list) and subject in weak_subjects:
                hours += weak_extra
            hours = round(hours / session_granularity) * session_granularity
            rows.append({'Day': day, 'Subject': subject, 'Hours': hours})
    df_detail = pd.DataFrame(rows)
    df_summary = df_detail.groupby('Day').agg({'Hours': 'sum'}).reset_index()
    total_hours = df_detail['Hours'].sum()
    target_hours = sum(predicted_hours_per_subject) * len(study_days)
    remaining = target_hours - total_hours
    return df_detail, df_summary, remaining, target_hours

new_student = pd.DataFrame({
    "Available_Hours_Per_Day": [4],
    "Free_Days_Per_Week": [5],
    "Weak_Subjects_Count": [2]
})

predicted_hours = [2, 3, 4, 2, 1, 2]
subject_names = ["Math", "Physics", "CS", "Chemistry", "English", "Biology"]
available_hours_per_day = int(new_student.loc[0, "Available_Hours_Per_Day"])
free_days_per_week = int(new_student.loc[0, "Free_Days_Per_Week"])
weak_subjects = int(new_student.loc[0, "Weak_Subjects_Count"])

df_detail, df_summary, remaining, target_hours = generate_weekly_schedule(
    predicted_hours_per_subject=predicted_hours,
    subject_names=subject_names,
    available_hours_per_day=available_hours_per_day,
    free_days_per_week=free_days_per_week,
    weak_subjects=weak_subjects,
    weak_extra=0.5,
    session_granularity=0.5
)

df_summary.to_csv("weekly_schedule_summary.csv", index=False)
df_detail.to_csv("weekly_schedule_detailed.csv", index=False)
